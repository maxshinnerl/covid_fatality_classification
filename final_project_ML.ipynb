{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from   sklearn.compose         import *\n",
    "from   sklearn.experimental    import enable_iterative_imputer\n",
    "from   sklearn.impute          import *\n",
    "from   sklearn.linear_model    import LinearRegression \n",
    "from   sklearn.linear_model    import LogisticRegression, RidgeClassifier\n",
    "from   sklearn.metrics         import mean_absolute_error\n",
    "from   sklearn.model_selection import train_test_split\n",
    "from   sklearn.pipeline        import Pipeline\n",
    "from   sklearn.preprocessing   import *\n",
    "from   sklearn.metrics         import balanced_accuracy_score\n",
    "from   sklearn.inspection      import permutation_importance\n",
    "from   sklearn.decomposition   import PCA\n",
    "from   sklearn.dummy           import DummyClassifier\n",
    "from   sklearn.ensemble        import RandomForestClassifier\n",
    "from   sklearn.model_selection import RandomizedSearchCV\n",
    "from   sklearn.base            import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/sub_COVID-19_Case_Surveillance_Public_Use_Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumption of Supervised Machine Learning is that each instance has a label.  We will discard instances with missing/unknown targets before beginning\n",
    "(Target transformations are ok to do outside of pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_target = df[(df['death_yn'] != 'Unknown') & (df['death_yn'] != 'Missing')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate target from rest of DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df_clean_target.drop('death_yn', axis=1)\n",
    "df_y = pd.DataFrame(df_clean_target['death_yn'])\n",
    "X = df_X.to_numpy()\n",
    "y = df_y.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train, validation, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pre, X_test, y_train_pre, y_test = train_test_split(X, y, train_size=0.8)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_pre, y_train_pre, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get categorical columns\n",
    "categorical_columns = (df_X.dtypes == object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continuous variable preprocessing pipeline\n",
    "con_pipe = Pipeline([('imputer', SimpleImputer(missing_values=np.nan, strategy='median', add_indicator=True)),\n",
    "                     ('scaler', StandardScaler())\n",
    "                    ])\n",
    "\n",
    "# categorical variable preprocessing pipeline\n",
    "cat_pipe = Pipeline([('imputer_nan', SimpleImputer(missing_values=np.nan, strategy='most_frequent', add_indicator=True)),\n",
    "                     ('imputer_missing', SimpleImputer(missing_values='Missing', strategy='most_frequent', add_indicator=True)),\n",
    "                     ('imputer_unknown', SimpleImputer(missing_values='Unknown', strategy='most_frequent', add_indicator=True)),\n",
    "                     ('ohe'    , OneHotEncoder(handle_unknown='ignore'))\n",
    "                    ])\n",
    "\n",
    "# combine preprocessing together\n",
    "preprocessing = ColumnTransformer([('categorical', cat_pipe, categorical_columns),\n",
    "                                   ('continuous' , con_pipe, ~categorical_columns)\n",
    "                                  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple attempt to get baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('prep' , preprocessing),\n",
    "                 ('lg' , LogisticRegression(solver='liblinear'))\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6945317725752509"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train.ravel())\n",
    "y_pred = pipe.predict(X_validate)\n",
    "balanced_accuracy_score(y_validate.ravel(), y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning and Cross Validation\n",
    "get hyperparams for LR, RF, Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestClassifier().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.0,\n",
       " 'class_weight': None,\n",
       " 'copy_X': True,\n",
       " 'fit_intercept': True,\n",
       " 'max_iter': None,\n",
       " 'normalize': False,\n",
       " 'random_state': None,\n",
       " 'solver': 'auto',\n",
       " 'tol': 0.001}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RidgeClassifier().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyEstimator(BaseEstimator):\n",
    "    \"Pass through class, methods are present but do nothing.\"\n",
    "    def fit(self): pass\n",
    "    def score(self): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "                 ('prep', preprocessing),\n",
    "                 ('clf', DummyEstimator())\n",
    "                ])\n",
    "\n",
    "search_space = [\n",
    "                 # LogisticRegression\n",
    "                 {'clf' : [LogisticRegression(solver='liblinear')],\n",
    "                  'clf__penalty': ['l1', 'l2'],\n",
    "                  'clf__C' : np.logspace(0, 4, 10),\n",
    "                  'clf__class_weight' : [None, 'balanced']\n",
    "                 },\n",
    "    \n",
    "                 # RidgeClassifier\n",
    "                 {'clf' : [RidgeClassifier(solver='auto')],\n",
    "                  'clf__tol' : [0.001, 0.01, 0.1],\n",
    "                  'clf__max_iter' : [None, 1, 10, 100, 1000],\n",
    "                  'clf__class_weight' : [None, 'balanced'],\n",
    "                  'clf__normalize' : [False, True]\n",
    "                 },\n",
    "                 \n",
    "                 # RandomForest\n",
    "                 {'clf' : [RandomForestClassifier(n_jobs=-1)],\n",
    "                  'clf__criterion' : ['gini', 'entropy'],\n",
    "                  'clf__class_weight' : [None, 'balanced'],\n",
    "                  'clf__max_depth' : list(range(2,11)),\n",
    "                  'clf__max_features' : ['auto', 'log2', 'sqrt'],\n",
    "                  'clf__n_estimators' : list(range(50, 250, 50)),\n",
    "                  'clf__bootstrap' : [True, False]\n",
    "                 }\n",
    "    \n",
    "    \n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_algos_rand = RandomizedSearchCV(estimator=pipe,\n",
    "                                    param_distributions=search_space,\n",
    "                                    scoring='balanced_accuracy',\n",
    "                                    n_iter=100,\n",
    "                                    cv=5,\n",
    "                                    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and get best model\n",
    "(uncomment to run, takes a few minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit it and see results\n",
    "# best_model = clf_algos_rand.fit(X_train, y_train.ravel())\n",
    "# best_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pipe = Pipeline([(\n",
    "                       'clf', RandomForestClassifier(class_weight='balanced',\n",
    "                                                     max_depth=10,\n",
    "                                                     max_features='sqrt',\n",
    "                                                     bootstrap=False,\n",
    "                                                     n_estimators = 150,\n",
    "                                                     n_jobs=-1,\n",
    "                                                     criterion='entropy')\n",
    ")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create end-to-end pipeline\n",
    "\n",
    "pipe = Pipeline([\n",
    "                 ('prep' , preprocessing),\n",
    "                 ('rf', clf_pipe )\n",
    "                ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model, get Balanced Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9042140468227424"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train.ravel())\n",
    "y_pred = pipe.predict(X_validate)\n",
    "bal = (balanced_accuracy_score(y_validate.ravel(), y_pred))\n",
    "bal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit against test set for final evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9055451505016723"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "                 ('prep' , preprocessing),\n",
    "                 ('rf', clf_pipe )\n",
    "                ])\n",
    "\n",
    "\n",
    "\n",
    "pipe.fit(X_train_pre, y_train_pre.ravel())\n",
    "y_pred = pipe.predict(X_test)\n",
    "bal = (balanced_accuracy_score(y_test.ravel(), y_pred))\n",
    "bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
